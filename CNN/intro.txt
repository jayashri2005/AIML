"convilutional neural network" - > even we flatten data it still remembers the spatial relationships ;
 for bigger data if we flatten it becomes a very high dimensional vector and it loses the spatial relationships.

 "flatten" - > converts 2D or 3D data to 1D data; for example a 2x2 matrix becomes a 1x4 vector

 "cnn"-> used in signal processing, image processing, etc.; 
 in signal processing 1 signal is convoluted with another signal to get a third signal

 in 1st matrix it consist [[0 1 0],[0 1 0][0 1 0]] *multiply with below pixel val
 when multiply 0 with below pix val it return 0 -black 

 i.e [[0 1 0]] * [[13 12 14]] = [ [0 12 0]] bcoz it only capture vertical lines remaining part zero 

 and to capture horiontal [0 0 0]
                     [1 1 1]
                     [0 0 0]

 more filter more angle to see img 
 it get multipled throughout entire img and the result of the product is summed to get the single result 

 "convolutional"-> only way to approx things as well as generalize 
 in multifling we add 1 layer of padding with zeros if 4*4 matrix we use 6 zero for padding top 

 "feature map"-> output of convolution operation; each filter produces one feature map; i.e 5*5 = 3*3 
 padding 5*5 -> 7*7 -> result 3*3 

 "padding"-> helps to maintain the resultant matrix as same size as the original img

 "filter"-> also called kernel; it is a small matrix that slides over the input data to extract features; it is a learnable parameter

"why use" -> to extract features from the input data; it helps to identify patterns in the data
preserving data structure 

while trinaing bulk data -> fix weight -> num of cal reduced 

"use softmax" -> produce probostic val -> it is applied after flattening 
"delayed mean" -> reduce size of img 

"max pooling" -> reduce size of img ; where we produce blur pics 

pooling -> types mx,avg

"max pooling" ->takes the max val in the given matrix val [[32 10][4 14]] -> 32
"avg pooling" -> takes the avg val in the given matrix val [[32 10][4 14]] -> 44/4 = 11

"kernal" - > othr name of filter 

1 filter - 1 feature map 
 input(kernal/filter applied) - > convolutional +relu -> "feature map{multi layer[to get edge features]}" -> 
 flatten layer -> fully connected layer -> softmax activation function -> output

 1st layer -> min detail -> nxt lvl la contextual data -> nxt layer
 1 -> div into half -> div into half -> nd so in the whole context is stored in "stack" 
 the it get flatttend

 https://developersbreach.com/convolution-neural-network-deep-learning/

 https://developer.nvidia.com/discover/convolution

 